{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtvXrU1KMpQpkprK9uosxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-unni/SET1/blob/main/webscrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y9ULS52YMK8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6dfaa0d-4464-46ca-fa61-7dd0c871bf53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "print(\"gay\")\n",
        "url = 'https://www.tripadvisor.in/AttractionProductReview-g304554-d16731994-Mumbai_Temple_Tour_in_Private_Vehicle-Mumbai_Maharashtra.html'\n",
        "response = requests.get(url)\n",
        "print(\"gay1\")\n",
        "if response.status_code == 200:\n",
        "    # Proceed with parsing the HTML content\n",
        "    print(\"gay1\")\n",
        "    page_content = response.text\n",
        "else:\n",
        "    print(f\"Request failed with status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(page_content, 'html.parser')\n",
        "# Use soup.select or soup.find to locate specific elements\n",
        "reviews = soup.select('.yCeTE')  # Example selector for review text\n"
      ],
      "metadata": {
        "id": "bOrK1_8kNvIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in reviews:\n",
        "    review_text = review.get_text()\n",
        "    print(review_text)\n"
      ],
      "metadata": {
        "id": "xvvNulqlRlHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fullproof code to collect reviews and user data from TripAdvisor\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "import time\n",
        "\n",
        "#User Details\n",
        "profiles_list=[]\n",
        "combined_data_list = []\n",
        "\n",
        "# default path to file to store data\n",
        "path_to_file = \"C:\\\\Users\\\\vishn\\\\Desktop\\\\SET1\\\\reviews.csv\"\n",
        "\n",
        "# default number of scraped pages\n",
        "# num_page = 700\n",
        "num_page = 2\n",
        "\n",
        "# default tripadvisor website of hotel or things to do (attraction/monument)\n",
        "# url = \"https://www.tripadvisor.in/AttractionProductReview-g304554-d16796488-Private_Full_Day_Mumbai_Sightseeing_Tour_with_Dharavi_Slums-Mumbai_Maharashtra.html\"\n",
        "url = \"https://www.tripadvisor.in/Attraction_Review-g304554-d321437-Reviews-Marine_Drive-Mumbai_Maharashtra.html\"\n",
        "\n",
        "# if you pass the inputs in the command line\n",
        "if (len(sys.argv) == 4):\n",
        "    path_to_file = sys.argv[1]\n",
        "    num_page = int(sys.argv[2])\n",
        "    url = sys.argv[3]\n",
        "\n",
        "# import the webdriver\n",
        "driver = webdriver.Chrome()\n",
        "driver.maximize_window()\n",
        "driver.get(url)\n",
        "\n",
        "# open the file to save the review\n",
        "csvFile = open(path_to_file, 'a', encoding=\"utf-8\")\n",
        "csvWriter = csv.writer(csvFile)\n",
        "\n",
        "column_headings = [\"Date\", \"Title\", \"Review\", \"Name\", \"Username\", \"Loaction\", \"Joined_Date\"]\n",
        "csvWriter.writerow(column_headings)\n",
        "\n",
        "# change the value inside the range to save more or less reviews\n",
        "for i in range(0, num_page):\n",
        "\n",
        "    # expand the review\n",
        "    time.sleep(2)\n",
        "\n",
        "    container = driver.find_elements(\"xpath\",\"//div[contains(@data-automation, 'reviewCard')]\")\n",
        "    dates = driver.find_elements(\"xpath\",\"//div[@class='biGQs _P pZUbB ncFvv osNWb']\")\n",
        "\n",
        "    for j in range(len(container)):\n",
        "        button = container[j].find_element(\"xpath\", \".//button//span[text()='Read more']/..\")\n",
        "        if button.is_displayed() and button.is_enabled():\n",
        "            button.click()\n",
        "        title = container[j].find_element(\"xpath\",\".//div[@class='biGQs _P fiohW qWPrE ncFvv fOtGX']/a/span\").text\n",
        "        review = container[j].find_element(\"xpath\",\".//div[@class='biGQs _P pZUbB KxBGd']/span[@class='yCeTE']\").text.replace(\"\\n\", \"  \")\n",
        "\n",
        "        profile_link = container[j].find_element(\"xpath\", \".//a[contains(@class, 'BMQDV')]\").get_attribute(\"href\")\n",
        "        profiles_list.append(profile_link)\n",
        "\n",
        "        if len(dates) > j:\n",
        "            date = \" \".join(dates[j].text.split(\" \")[-2:])\n",
        "        else:\n",
        "            date = \"Date Not Available\"\n",
        "\n",
        "#         date = \" \".join(dates[j].text.split(\" \")[-2:])\n",
        "#         csvWriter.writerow([date, title, review])\n",
        "        combined_data = {\n",
        "            \"Date\": date,\n",
        "            \"Title\": title,\n",
        "            \"Review\": review,\n",
        "            \"Name\": \"\",\n",
        "            \"Username\": \"\",\n",
        "            \"Location\": \"\",\n",
        "            \"Joined_Date\": \"\"\n",
        "        }\n",
        "        combined_data_list.append(combined_data)\n",
        "\n",
        "    # change the page\n",
        "    try:\n",
        "        nextbutton=driver.find_element(\"xpath\",\".//a[contains(@data-smoke-attr,'pagination-next-arrow')]\")\n",
        "        if nextbutton.is_displayed() and nextbutton.is_enabled():\n",
        "            nextbutton.click()\n",
        "        else:\n",
        "            print(\"Reached the last page.\")\n",
        "            break\n",
        "    except NoSuchElementException:\n",
        "        print(\"Pagination element not found. Reached the last page.\")\n",
        "        break\n",
        "\n",
        "\n",
        "iteration = 1\n",
        "\n",
        "for profile_url in profiles_list:\n",
        "\n",
        "    driver.get(profile_url)\n",
        "    time.sleep(2)\n",
        "\n",
        "    intro = driver.find_element(\"xpath\", \"//div[contains(@class, 'Me Nb MD NC')]\")\n",
        "\n",
        "    try:\n",
        "        loc = intro.find_element(\"xpath\", \".//span[@class='PacFI _R S4 H3 LXUOn default']\").text\n",
        "    except NoSuchElementException:\n",
        "        loc = \"Location Not Available\"\n",
        "\n",
        "    try:\n",
        "        joined = intro.find_element(\"xpath\", \".//span[@class='ECVao _R H3']\").text\n",
        "    except NoSuchElementException:\n",
        "        joined = \"Joined Date Not Available\"\n",
        "\n",
        "    user_info = driver.find_element(\"xpath\", \"//span[@class='ecLBS _R shSnD']\")\n",
        "\n",
        "    try:\n",
        "        username = user_info.find_element(\"xpath\", \".//span[@class='Dsdjn _R']\").text\n",
        "    except NoSuchElementException:\n",
        "        username = \"Username Not Available\"\n",
        "\n",
        "    try:\n",
        "        name = user_info.find_elements(\"xpath\", \".//span[@class='JWmxy']/h1/span[@class='OUDwj b brsfY']\")[0].text\n",
        "    except (IndexError, NoSuchElementException):\n",
        "        name = \"Name Not Available\"\n",
        "\n",
        "#     print(\"For iteration \", iteration, \": \", \"name, username, joined, loc: \\n\", name, \"\\n\", username, \"\\n\", joined, \"\\n\", loc, \"\\n\")\n",
        "#     csvWriter.writerow([\"\", \"\", \"\", name, username, loc, joined])\n",
        "    combined_data = combined_data_list[iteration - 1]\n",
        "    combined_data[\"Name\"] = name\n",
        "    combined_data[\"Username\"] = username\n",
        "    combined_data[\"Location\"] = loc\n",
        "    combined_data[\"Joined_Date\"] = joined\n",
        "\n",
        "    iteration+=1\n",
        "\n",
        "for data in combined_data_list:\n",
        "    csvWriter.writerow([data[\"Date\"], data[\"Title\"], data[\"Review\"], data[\"Name\"], data[\"Username\"], data[\"Location\"], data[\"Joined_Date\"]])\n",
        "\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "b4zJmYn9RnWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fullproof code to collect reviews and user data from TripAdvisor of multiplePlaces\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "import time\n",
        "import multiprocessing\n",
        "\n",
        "\n",
        "def scrape_and_append_reviews(url, destination_code):\n",
        "    #User Details\n",
        "    profiles_list=[]\n",
        "    combined_data_list = []\n",
        "\n",
        "    # default number of scraped pages\n",
        "    num_page = 50\n",
        "\n",
        "    # default path to file to store data\n",
        "    path_to_file = \"C:\\\\Users\\\\vishn\\\\Desktop\\\\SET1\\\\reviews_\" + destination_code + \".csv\"\n",
        "\n",
        "    # open the file to save the review\n",
        "    csvFile = open(path_to_file, 'a', encoding=\"utf-8\")\n",
        "    csvWriter = csv.writer(csvFile)\n",
        "\n",
        "    column_headings = [\"Date\", \"Title\", \"Review\", \"Destination_ID\", \"Name\", \"Username\", \"Location\", \"Joined_Date\"]\n",
        "    csvWriter.writerow(column_headings)\n",
        "\n",
        "    # import the webdriver\n",
        "    driver = webdriver.Chrome(options=webdriver.ChromeOptions().add_argument('--headless'))\n",
        "    driver.maximize_window()\n",
        "    driver.get(url)\n",
        "\n",
        "    # change the value inside the range to save more or less reviews\n",
        "    for i in range(0, num_page):\n",
        "\n",
        "        # expand the review\n",
        "        time.sleep(2)\n",
        "\n",
        "        container = driver.find_elements(\"xpath\",\"//div[contains(@data-automation, 'reviewCard')]\")\n",
        "        dates = driver.find_elements(\"xpath\",\"//div[@class='biGQs _P pZUbB ncFvv osNWb']\")\n",
        "\n",
        "        for j in range(len(container)):\n",
        "            button = container[j].find_element(\"xpath\", \".//button//span[text()='Read more']/..\")\n",
        "            if button.is_displayed() and button.is_enabled():\n",
        "                button.click()\n",
        "            title = container[j].find_element(\"xpath\",\".//div[@class='biGQs _P fiohW qWPrE ncFvv fOtGX']/a/span\").text\n",
        "            review = container[j].find_element(\"xpath\",\".//div[@class='biGQs _P pZUbB KxBGd']/span[@class='yCeTE']\").text.replace(\"\\n\", \"  \")\n",
        "\n",
        "            profile_link = container[j].find_element(\"xpath\", \".//a[contains(@class, 'BMQDV')]\").get_attribute(\"href\")\n",
        "            profiles_list.append(profile_link)\n",
        "\n",
        "            if len(dates) > j:\n",
        "                date = \" \".join(dates[j].text.split(\" \")[-2:])\n",
        "            else:\n",
        "                date = \"Date Not Available\"\n",
        "\n",
        "            combined_data = {\n",
        "                \"Date\": date,\n",
        "                \"Title\": title,\n",
        "                \"Review\": review,\n",
        "                \"Destination_ID\": destination_code,\n",
        "                \"Name\": \"\",\n",
        "                \"Username\": \"\",\n",
        "                \"Location\": \"\",\n",
        "                \"Joined_Date\": \"\"\n",
        "\n",
        "            }\n",
        "            combined_data_list.append(combined_data)\n",
        "\n",
        "\n",
        "        # change the page\n",
        "        try:\n",
        "            nextbutton=driver.find_element(\"xpath\",\".//a[contains(@data-smoke-attr,'pagination-next-arrow')]\")\n",
        "            if nextbutton.is_displayed() and nextbutton.is_enabled():\n",
        "                nextbutton.click()\n",
        "            else:\n",
        "                print(\"Reached the last page.\")\n",
        "                break\n",
        "        except NoSuchElementException:\n",
        "            print(\"Pagination element not found. Reached the last page.\")\n",
        "            break\n",
        "\n",
        "\n",
        "    iteration = 0\n",
        "\n",
        "    for profile_url in profiles_list:\n",
        "\n",
        "        driver.get(profile_url)\n",
        "        time.sleep(2)\n",
        "\n",
        "        intro = driver.find_element(\"xpath\", \"//div[contains(@class, 'Me Nb MD NC')]\")\n",
        "\n",
        "        try:\n",
        "            loc = intro.find_element(\"xpath\", \".//span[@class='PacFI _R S4 H3 LXUOn default']\").text\n",
        "        except NoSuchElementException:\n",
        "            loc = \"Location Not Available\"\n",
        "\n",
        "        try:\n",
        "            joined = intro.find_element(\"xpath\", \".//span[@class='ECVao _R H3']\").text\n",
        "        except NoSuchElementException:\n",
        "            joined = \"Joined Date Not Available\"\n",
        "\n",
        "        user_info = driver.find_element(\"xpath\", \"//span[@class='ecLBS _R shSnD']\")\n",
        "\n",
        "        try:\n",
        "            username = user_info.find_element(\"xpath\", \".//span[@class='Dsdjn _R']\").text\n",
        "        except NoSuchElementException:\n",
        "            username = \"Username Not Available\"\n",
        "\n",
        "        try:\n",
        "            name = user_info.find_elements(\"xpath\", \".//span[@class='JWmxy']/h1/span[@class='OUDwj b brsfY']\")[0].text\n",
        "        except (IndexError, NoSuchElementException):\n",
        "            name = \"Name Not Available\"\n",
        "\n",
        "        combined_data = combined_data_list[iteration - 1]\n",
        "        combined_data[\"Name\"] = name\n",
        "        combined_data[\"Username\"] = username\n",
        "        combined_data[\"Location\"] = loc\n",
        "        combined_data[\"Joined_Date\"] = joined\n",
        "\n",
        "        iteration+=1\n",
        "\n",
        "    for data in combined_data_list:\n",
        "        csvWriter.writerow([data[\"Date\"], data[\"Title\"], data[\"Review\"], data[\"Destination_ID\"], data[\"Name\"], data[\"Username\"], data[\"Location\"], data[\"Joined_Date\"]])\n",
        "\n",
        "    driver.quit()\n",
        "\n",
        "scrape_and_append_reviews(\"https://www.tripadvisor.in/Attraction_Review-g304554-d311661-Reviews-Colaba-Mumbai_Maharashtra.html\", \"COL\")"
      ],
      "metadata": {
        "id": "cYNQB1ZHR0l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "import time\n",
        "import multiprocessing\n",
        "from scrapper import scrape_and_append_reviews\n",
        "\n",
        "code_to_name = {\n",
        "    \"GWOI\": \"Gateway Of India\",\n",
        "    \"MD\": \"Marine Drive\",\n",
        "    \"SHSI\" : \"Shree Siddhivinayak\",\n",
        "    \"BWS\" : \"Bandra-Worli Sea Link\",\n",
        "    \"CST\" : \"Chhatrapati Shivaji Terminus\",\n",
        "    \"KZM\" : \"KidZania Mumbai\",\n",
        "    \"MBGM\" : \"Mani Bhavan Gandhi Museum\",\n",
        "    \"COL\" : \"Colaba\",\n",
        "    \"ELC\" : \"Elephanta Caves\",\n",
        "    \"NP\" : \"Nariman Point\",\n",
        "    \"GVP\" : \"Global Vipassana Pagoda\",\n",
        "    \"KC\" : \"Kanheri Caves\",\n",
        "    \"MMB\" : \"Mount Mary Basilica\",\n",
        "    \"CSMVS\" : \"Chhatrapati Shivaji Maharaj Vastu Sangrahalaya\",\n",
        "    \"EW\" : \"Essel World\",\n",
        "    \"SSRGP\" : \"Sri Sri Radha Gopinath Temple\",\n",
        "    \"JB\" : \"Juhu Beach\"\n",
        "}\n",
        "\n",
        "code_to_url = {\n",
        "    \"GWOI\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d311667-Reviews-Gateway_of_India-Mumbai_Maharashtra.html\",\n",
        "    \"MD\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d321437-Reviews-Marine_Drive-Mumbai_Maharashtra.html\",\n",
        "    \"SHSI\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d622586-Reviews-Shree_Siddhivinayak-Mumbai_Maharashtra.html\",\n",
        "    \"BWS\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d2704519-Reviews-Bandra_Worli_Sea_Link-Mumbai_Maharashtra.html\",\n",
        "    \"CST\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d321412-Reviews-Chhatrapati_Shivaji_Terminus-Mumbai_Maharashtra.html\",\n",
        "    \"KZM\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d4817230-Reviews-KidZania_Mumbai-Mumbai_Maharashtra.html\",\n",
        "    \"MBGM\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d311674-Reviews-Mani_Bhavan_Gandhi_Museum-Mumbai_Maharashtra.html\",\n",
        "    \"COL\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d311661-Reviews-Colaba-Mumbai_Maharashtra.html\",\n",
        "    \"ELC\" : \"https://www.tripadvisor.in/AttractionProductReview-g304554-d19066869-Elephanta_Caves_Mumbai_Excursion-Mumbai_Maharashtra.html\",\n",
        "    \"NP\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d3783379-Reviews-Nariman_Point-Mumbai_Maharashtra.html\",\n",
        "    \"GVP\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d2514810-Reviews-Global_Vipassana_Pagoda-Mumbai_Maharashtra.html\",\n",
        "    \"KC\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d1204502-Reviews-Kanheri_Caves-Mumbai_Maharashtra.html\",\n",
        "    \"MMB\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d2638424-Reviews-Mount_Mary_Basilica-Mumbai_Maharashtra.html\",\n",
        "    \"CSMVS\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d10071803-Reviews-Chhatrapati_Shivaji_Maharaj_Vastu_Sangrahalaya-Mumbai_Maharashtra.html\",\n",
        "    \"EW\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d321430-Reviews-Essel_World-Mumbai_Maharashtra.html\",\n",
        "    \"SSRGP\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d3207759-Reviews-Sri_Sri_Radha_Gopinath_Temple-Mumbai_Maharashtra.html\",\n",
        "    \"JB\" : \"https://www.tripadvisor.in/Attraction_Review-g304554-d321424-Reviews-Juhu_Beach-Mumbai_Maharashtra.html\"\n",
        "}\n",
        "\n",
        "list_of_destinations = [\"GWOI\", \"SHSI\", \"CST\"]\n",
        "# list_of_destinations = [\"GWOI\", \"MD\", \"SHSI\", \"BWS\", \"CST\", \"KZM\", \"MBGM\", \"COL\", \"ELC\", \"NP\", \"GVP\", \"KC\", \"MMB\", \"CSMVS\", \"EW\", \"SSRGP\", \"JB\"]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args_list = []\n",
        "\n",
        "    for i in list_of_destinations:\n",
        "        tup = (code_to_url[i], i)\n",
        "        args_list.append(tup)\n",
        "\n",
        "    processes = []\n",
        "    for args in args_list:\n",
        "        process = multiprocessing.Process(target=scrape_and_append_reviews, args=args)\n",
        "        processes.append(process)\n",
        "        process.start()\n",
        "\n",
        "    for process in processes:\n",
        "        process.join()"
      ],
      "metadata": {
        "id": "BcRbuSLoR3QL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}